#!/usr/bin/env python3
"""
Parse the GISAID JSON load into a metadata tsv and a FASTA file.
"""
import argparse
from pathlib import Path
import fsspec
import pandas as pd


# Note: 'sequence' should NEVER appear in these lists!
METADATA_COLUMNS = [  # Ordering of columns in the existing metadata.tsv in the ncov repo
    'strain', 'virus', 'gisaid_epi_isl', 'genbank_accession', 'date', 'region',
    'country', 'division', 'location', 'region_exposure', 'country_exposure',
    'division_exposure', 'segment', 'length', 'host', 'age', 'sex',
    'originating_lab', 'submitting_lab', 'authors', 'url', 'title',
    'date_submitted'
]

# Preserve the ordering of these columns for ease when generating Slack
# notifications on change
ADDITIONAL_INFO_COLUMNS = [
    'gisaid_epi_isl', 'strain', 'additional_host_info',
    'additional_location_info'
]

assert 'sequence' not in METADATA_COLUMNS, "Sequences should not appear in metadata!"
assert 'sequence' not in ADDITIONAL_INFO_COLUMNS, "Sequences should not appear in additional info!"

def preprocess(gisaid_data: pd.DataFrame) -> pd.DataFrame:
    """
    Renames columns and abbreviate strain name in a given *gisaid_data*
    DataFrame, returning the modified DataFrame.
    """
    mapper = {
        'covv_virus_name'       : 'strain',
        'covv_accession_id'     : 'gisaid_epi_isl',
        'covv_collection_date'  : 'date',
        'covv_host'             : 'host',
        'covv_orig_lab'         : 'originating_lab',
        'covv_subm_lab'         : 'submitting_lab',
        'covv_authors'          : 'authors',
        'covv_patient_age'      : 'age',
        'covv_gender'           : 'sex',
        'covv_add_host_info'    : 'additional_host_info',
        'covv_add_location'     : 'additional_location_info',
        'covv_subm_date'        : 'date_submitted',
        'covv_location'         : 'location',
    }

    # If an expected field is missing, fill it with NAs so the rest of the
    # script can assume it exists.
    for field in mapper:
        if field not in gisaid_data:
            gisaid_data[field] = pd.NA

    gisaid_data.rename(mapper, axis="columns", inplace=True)

    # Calculate sequence length.  GISAID provides a "sequence_length" column,
    # but it sometimes inexplicably goes missing.
    gisaid_data['sequence'] = gisaid_data['sequence'].str.replace('\n', '')
    gisaid_data['length'] = gisaid_data['sequence'].str.len().astype("Int64")

    # Abbreviate strain names by removing the prefix. Strip spaces, too.
    gisaid_data['strain'] = gisaid_data['strain'] \
        .str.replace(r'^[hn]CoV-19/', '', n=1, case=False) \
        .str.replace(r'\s', '')

    # Drop entries with length less than 15kb
    gisaid_data.drop(gisaid_data[gisaid_data.length < 15000].index, inplace=True)

    # Drop duplicates, prefer longest and earliest sequence (assuming accessions
    # are chronological)
    gisaid_data.sort_values(['strain', 'length', 'gisaid_epi_isl'],
        ascending=[True, False, True], inplace=True)

    gisaid_data.drop_duplicates('strain', inplace=True)

    # Sort by strain name
    gisaid_data.sort_values(by=['strain'], inplace=True)

    return gisaid_data

def parse_geographic_columns(gisaid_data: pd.DataFrame) -> pd.DataFrame:
    """
    Expands the string found in the column named `location` in the given
    *df*, creating four new columns. Returns the modified ``pd.DataFrame``.
    """
    geographic_data = gisaid_data['location'].str.split('\s*/\s*', expand=True)

    gisaid_data['region']      = geographic_data[0]
    gisaid_data['country']     = geographic_data[1]
    gisaid_data['division']    = geographic_data[2]
    gisaid_data['location']    = geographic_data[3]


    return gisaid_data

def parse_originating_lab(gisaid_data: pd.DataFrame) -> pd.DataFrame:
    """
    Parses originating lab
    """
    # Fix accents and non-standard commas
    gisaid_data['originating_lab'] = gisaid_data['originating_lab'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')
    # Strip and normalize whitespace
    gisaid_data['originating_lab'] = gisaid_data['originating_lab'].str.strip().str.replace(r'\s+', ' ')
    # Fix common spelling mistakes
    gisaid_data['originating_lab'] = gisaid_data['originating_lab'].str.replace('Contorl', 'Control')
    gisaid_data['originating_lab'] = gisaid_data['originating_lab'].str.replace('Dieases', 'Disease')
    return gisaid_data

def parse_submitting_lab(gisaid_data: pd.DataFrame) -> pd.DataFrame:
    """
    Parses submitting lab
    """
    # Fix accents and non-standard commas
    gisaid_data['submitting_lab'] = gisaid_data['submitting_lab'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')
    # Strip and normalize whitespace
    gisaid_data['submitting_lab'] = gisaid_data['submitting_lab'].str.strip().str.replace(r'\s+', ' ')
    # Fix common spelling mistakes
    gisaid_data['submitting_lab'] = gisaid_data['submitting_lab'].str.replace('Contorl', 'Control')
    gisaid_data['submitting_lab'] = gisaid_data['submitting_lab'].str.replace('Dieases', 'Disease')
    return gisaid_data

def parse_authors(gisaid_data: pd.DataFrame) -> pd.DataFrame:
    """
    Abbreviates the column named `authors` to be "Zhang et al" rather than a
    full list
    """
    # Fix accents and non-standard commas
    gisaid_data['authors'] = gisaid_data['authors'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')
    # Strip and normalize whitespace
    gisaid_data['authors'] = gisaid_data['authors'].str.strip().str.replace(r'\s+', ' ')
    # Strip to string before first comma
    gisaid_data['authors'] = gisaid_data['authors'].str.replace(r"^([^,]+),.+", lambda m: m.group(1))
    # Strip to string before first semicolon
    gisaid_data['authors'] = gisaid_data['authors'].str.replace(r"^([^;]+);.+", lambda m: m.group(1))
    # Convert this string to last name
    gisaid_data['authors'] = gisaid_data['authors'].str.replace(r" [A-Z]\.? ", ' ')
    gisaid_data['authors'] = gisaid_data['authors'].str.replace(r"^[A-Z][a-z]+\-?[A-Z]?[a-z]* ([A-Z][a-z]+) *$", lambda m: m.group(1))
    gisaid_data['authors'] = gisaid_data['authors'].str.replace(r" [A-Z]\.?[A-Z]?\.?$", '')
    gisaid_data['authors'] = gisaid_data['authors'].str.replace(r" [A-Z]-[A-Z]$", '')
    # Add et al
    gisaid_data['authors'] = gisaid_data['authors'].astype(str) + ' et al'
    return gisaid_data

def parse_age(gisaid_data: pd.DataFrame) -> pd.DataFrame:
    """
    Parse patient age.
    """
    # Fix accents and non-standard commas
    gisaid_data['age'] = gisaid_data['age'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')
    # Convert "60s" or "50's" to "?"
    gisaid_data['age'] = gisaid_data['age'].str.replace(r"^\d+\'?[A-Za-z]", '?')
    # Convert to just number
    gisaid_data['age'] = gisaid_data['age'].str.replace(r"^(\d+) years$", lambda m: m.group(1))
    # Convert months to years
    gisaid_data['age'] = gisaid_data['age'].str.replace(r"^(\d+) months", lambda m: str(int(m.group(1))/12.0))
    # Cleanup unknowns
    gisaid_data['age'] = gisaid_data['age'].str.replace(r"^0$", '?')
    # Catch all non-numeric values
    gisaid_data['age'] = pd.to_numeric(gisaid_data['age'], errors='coerce').fillna('?')
    # Convert numeric values to int
    gisaid_data['age'] = gisaid_data['age'].apply(lambda x: x if x=='?' else int(x))
    return gisaid_data

def parse_sex(gisaid_data: pd.DataFrame) -> pd.DataFrame:
    """
    Parse patient sex.
    """
    # Fix accents and non-standard commas
    gisaid_data['sex'] = gisaid_data['sex'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')
    # Casing and abbreviations
    gisaid_data['sex'] = gisaid_data['sex'].str.replace(r"^male$", 'Male')
    gisaid_data['sex'] = gisaid_data['sex'].str.replace(r"^M$", 'Male')
    gisaid_data['sex'] = gisaid_data['sex'].str.replace(r"^female$", 'Female')
    gisaid_data['sex'] = gisaid_data['sex'].str.replace(r"^F$", 'Female')
    # Fix spelling
    gisaid_data['sex'] = gisaid_data['sex'].str.replace(r"^Femal$", 'Female')
    # Cleanup unknowns
    gisaid_data['sex'] = gisaid_data['sex'].str.replace(r"^unknown$", '?')
    gisaid_data['sex'] = gisaid_data['sex'].str.replace(r"^N/A$", '?')
    gisaid_data['sex'] = gisaid_data['sex'].str.replace(r"^NA$", '?')
    gisaid_data['sex'] = gisaid_data['sex'].str.replace(r"^not applicable$", '?')
    return gisaid_data

def generate_hardcoded_metadata(hardcoded_metadata: pd.DataFrame) -> pd.DataFrame:
    """
    Returns a ``pd.DataFrame`` with a column for strain ID plus additional
    columns containing harcoded metadata.
    """
    hardcoded_metadata = pd.DataFrame(gisaid_data['strain'])
    hardcoded_metadata['virus']             = 'ncov'
    hardcoded_metadata['genbank_accession'] = '?'
    hardcoded_metadata['url']               = 'https://www.gisaid.org'
    # TODO verify these are all actually true
    hardcoded_metadata['segment']           = 'genome'
    hardcoded_metadata['title']             = '?'

    return hardcoded_metadata

def write_fasta_file(sequence_data: pd.DataFrame):
    """ """
    with fsspec.open(str(args.output_fasta), 'wt') as fastafile:
        for index, row in sequence_data.iterrows():
            fastafile.write(f">{row['strain']}\n")
            fastafile.write(f"{row['sequence']}\n")

def update_metadata(curated_gisaid_data: pd.DataFrame) -> pd.DataFrame:
    """ """
    # Add hardcoded metadata which is *almost* always true
    hardcoded_metadata = generate_hardcoded_metadata(curated_gisaid_data)
    curated_gisaid_data.update(hardcoded_metadata)
    curated_gisaid_data = curated_gisaid_data.merge(hardcoded_metadata)

    if args.annotations:
        # Use the curated annotations tsv to update any column values
        user_provided_annotations = pd.read_csv(args.annotations, header=None, sep='\t', comment="#")
        for index, (strain, key, value) in user_provided_annotations.iterrows():
            # Strip any whitespace remaining from inline comments after the final column.
            if isinstance(value, str):
                value = value.rstrip()
            curated_gisaid_data.loc[curated_gisaid_data['strain'] == strain, key] = value

    # Set `region_exposure` equal to `region` if it wasn't added by annotations
    if 'region_exposure' in curated_gisaid_data:
        curated_gisaid_data['region_exposure'].fillna(curated_gisaid_data['region'], inplace=True)
    else:
        curated_gisaid_data['region_exposure'] = curated_gisaid_data['region']

    # Set `country_exposure` equal to `country` if it wasn't added by annotations
    if 'country_exposure' in curated_gisaid_data:
        curated_gisaid_data['country_exposure'].fillna(curated_gisaid_data['country'], inplace=True)
    else:
        curated_gisaid_data['country_exposure'] = curated_gisaid_data['country']

    # Set `division_exposure` equal to `division` if it wasn't added by annotations
    if 'division_exposure' in curated_gisaid_data:
        curated_gisaid_data['division_exposure'].fillna(curated_gisaid_data['division'], inplace=True)
    else:
        curated_gisaid_data['division_exposure'] = curated_gisaid_data['division']

    # if division is blank, replace with country data, to avoid unexpected effects when subsampling by division
    # (where an empty division is counted as a 'division' group)
    curated_gisaid_data.loc[pd.isnull(curated_gisaid_data['division']), 'division'] = curated_gisaid_data['country']

    return curated_gisaid_data


if __name__ == '__main__':
    base = Path(__file__).resolve().parent.parent

    parser = argparse.ArgumentParser(
        description="Parse a GISAID JSON load into a metadata tsv and FASTA file.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("gisaid_data",
        default="s3://nextstrain-ncov-private/gisaid.ndjson.gz",
        nargs="?",
        help="Newline-delimited GISAID JSON data")
    parser.add_argument("--annotations",
        default=base / "source-data/annotations.tsv",
        help="Optional manually curated annotations TSV.\n"
            "The TSV file should have no header and exactly three columns which contain:\n\t"
            "1. the strain ID\n\t"
            "2. the column name to replace from the generated `metadata.tsv` file\n\t"
            "3. the replacement data\n"
        "Lines or parts of lines starting with '#' are treated as comments.\n"
        "e.g.\n\t"
        "USA/MA1/2020    location    Boston\n\t"
        "# First Californian sample\n\t"
        "USA/CA1/2020    genbank_accession   MN994467\n\t"
        "Wuhan-Hu-1/2019 collection_date 2019-12-26 # Manually corrected date")
    parser.add_argument("--output-metadata",
        default=base / "data/metadata.tsv",
        help="Output location of generated metadata tsv. Defaults to `data/metadata.tsv`")
    parser.add_argument("--output-fasta",
        default=base / "data/sequences.fasta",
        help="Output location of generated FASTA file. Defaults to `data/sequences.fasta`")
    parser.add_argument("--output-additional-info",
        default=base / "data/additional_info.tsv",
        help="Output location of additional info tsv. Defaults to `data/additional_info.tsv`")
    args = parser.parse_args()


    gisaid_data = pd.read_json(args.gisaid_data, lines=True, compression='infer')
    gisaid_data = preprocess(gisaid_data)
    write_fasta_file(gisaid_data)

    gisaid_data = parse_geographic_columns(gisaid_data)
    gisaid_data = parse_originating_lab(gisaid_data)
    gisaid_data = parse_submitting_lab(gisaid_data)
    gisaid_data = parse_authors(gisaid_data)
    gisaid_data = parse_age(gisaid_data)
    gisaid_data = parse_sex(gisaid_data)
    gisaid_data = update_metadata(gisaid_data)


    # Export additional info
    gisaid_data[ADDITIONAL_INFO_COLUMNS] \
        .to_csv(args.output_additional_info, sep='\t', na_rep='?', index=False)

    # Reorder columns consistent with the existing metadata on GitHub
    gisaid_data = gisaid_data[METADATA_COLUMNS]
    gisaid_data.to_csv(args.output_metadata, sep='\t', na_rep='', index=False)
